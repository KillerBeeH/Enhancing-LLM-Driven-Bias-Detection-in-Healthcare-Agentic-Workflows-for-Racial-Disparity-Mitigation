# Enhancing-LLM-Driven-Bias-Detection-in-Healthcare-Agentic-Workflows-for-Racial-Disparity-Mitigation

This repository contains the data and code for the paper ‚ÄúEnhancing LLM-Driven Bias Detection in Healthcare: Agentic Workflows for Racial Disparity Mitigation.‚Äù
It includes baseline data, model and agent outputs, and experiment code.

## Folder Structure

1. Baseline Data

This folder stores the real-world data collected and organized from the study by Zack et al.
Their original GitHub repository can be found here:
üëâ https://github.com/elehman16/gpt4_bias

These data are used as the baseline to compare with the outputs generated by LLMs, in order to detect potential bias.

2. LLMs Output Data

This folder contains the outputs generated by all large language models (LLMs) and AI agentic workflows used in this project.
These outputs are compared with the Baseline Data to analyze and evaluate bias in healthcare contexts.

3. Code of Colab / Exp I and Exp II

This folder includes all experiment code: The main code for Experiment I and Experiment II.

Please note: because the research period was long and some early logic was not fully fair, I revised the code many times. As a result, the overall structure may look a bit complex. Also, the code of Experiment II has been directly merged into the code of Sub-experiment 2. Some code was run again based on earlier runs, with different objects. Because of this, the outputs may look incomplete. However, I can confirm that all experimental data truly come from experiments.

About comments in the code:

I only added comments the first time a key step appears. For repeated or similar parts, I did not add comments again.


üîë Important Note:
All secret keys related to external resources (e.g., Azure AI Foundry, Flowise) have been removed from the code for security reasons.
